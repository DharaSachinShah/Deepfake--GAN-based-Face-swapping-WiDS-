{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1b3c92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.3934e-42,  0.0000e+00,  1.1210e-44,  0.0000e+00],\n",
      "         [-2.9198e+10,  5.5912e-43, -2.9198e+10,  5.5912e-43],\n",
      "         [-5.5100e-18,  5.5912e-43,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-5.5098e-18,  5.5912e-43,  2.3934e-42,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00, -4.1646e-18,  5.5912e-43],\n",
      "         [ 2.3934e-42,  0.0000e+00, -3.2404e+10,  5.5912e-43]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.empty(2,3,4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2c05cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0078e+00, 0.0000e+00, 8.9683e-44])\n"
     ]
    }
   ],
   "source": [
    "c=torch.empty(3)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9152b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2799, 0.2594, 0.8777])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0286e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2553, 0.0279, 0.5449],\n",
      "        [0.9595, 0.8933, 0.7663]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.rand(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55c0f722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.zeros(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a73ee703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.ones(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6c49555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int32\n",
      "torch.int64\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(3,3)\n",
    "print(torch.ones(3,3).dtype)\n",
    "print(torch.ones(3,3,dtype=torch.int).dtype)\n",
    "print(torch.ones(3,3,dtype=int).dtype)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ba731de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5000, 2.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([1.5,2.5,3.5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e819bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1094, 0.9850],\n",
      "        [0.0834, 0.0759]]) tensor([[0.6941, 0.4725],\n",
      "        [0.9357, 0.1885]])\n",
      "tensor([[0.8035, 1.4574],\n",
      "        [1.0192, 0.2643]])\n",
      "tensor([[0.8035, 1.4574],\n",
      "        [1.0192, 0.2643]])\n",
      "tensor([[0.0879, 1.4355],\n",
      "        [0.0850, 0.0201]])\n",
      "tensor([[0.0879, 1.4355],\n",
      "        [0.0850, 0.0201]])\n",
      "tensor([[0.0879, 1.4355],\n",
      "        [0.0850, 0.0201]])\n",
      "tensor([[ 0.0215, -0.4506],\n",
      "        [-0.0016,  0.0558]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(2,2)\n",
    "y=torch.rand(2,2)\n",
    "print(x,y)\n",
    "print(torch.add(x,y))\n",
    "print(y.add_(x))\n",
    "print(x*y)\n",
    "print(torch.mul(x,y))\n",
    "print(y.mul_(x))\n",
    "print(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "347a42b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8036, 0.8619, 0.4639],\n",
      "        [0.3657, 0.1318, 0.4954],\n",
      "        [0.3498, 0.4657, 0.4271]]) tensor(0.1318)\n",
      "tensor(0.1318)\n",
      "tensor([[0.8619, 0.4639],\n",
      "        [0.1318, 0.4954],\n",
      "        [0.4657, 0.4271]])\n",
      "tensor([[0.8036],\n",
      "        [0.3657],\n",
      "        [0.3498]])\n",
      "tensor([[0.8619, 0.4639],\n",
      "        [0.1318, 0.4954]])\n",
      "0.13181179761886597\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(3,3)\n",
    "print(x,x[1][1])\n",
    "print(x[1,1])\n",
    "print(x[:,1:])\n",
    "print(x[:,:1])\n",
    "print(x[0:2,1:3])\n",
    "print(x[1,1].item()) #exact value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4117ccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0611, 0.9250, 0.5628, 0.0593],\n",
      "        [0.4462, 0.3236, 0.6351, 0.7923],\n",
      "        [0.4098, 0.0287, 0.3355, 0.7233],\n",
      "        [0.1666, 0.5209, 0.2663, 0.7204]])\n",
      "tensor([0.0611, 0.9250, 0.5628, 0.0593, 0.4462, 0.3236, 0.6351, 0.7923, 0.4098,\n",
      "        0.0287, 0.3355, 0.7233, 0.1666, 0.5209, 0.2663, 0.7204])\n",
      "tensor([[0.0611, 0.9250, 0.5628, 0.0593, 0.4462, 0.3236, 0.6351, 0.7923],\n",
      "        [0.4098, 0.0287, 0.3355, 0.7233, 0.1666, 0.5209, 0.2663, 0.7204]])\n",
      "torch.Size([2, 8])\n",
      "tensor([[0.0611, 0.9250, 0.5628, 0.0593],\n",
      "        [0.4462, 1.0000, 0.6351, 0.7923],\n",
      "        [0.4098, 0.0287, 0.3355, 0.7233],\n",
      "        [0.1666, 0.5209, 0.2663, 0.7204]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(4,4)\n",
    "print(x)\n",
    "y=x.view(16)\n",
    "print(y)\n",
    "y=x.view(-1,8)\n",
    "print(y)\n",
    "print(y.size())\n",
    "x[1][1]=1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5cd5558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "<class 'torch.Tensor'>\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]]) [[2. 2.]\n",
      " [2. 2.]]\n",
      "[1. 1.] tensor([1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=torch.ones(2,2)\n",
    "print(a)\n",
    "print(type(a))\n",
    "b=a.numpy() #to get a numpy array\n",
    "print(b)\n",
    "print(type(b))\n",
    "a.add_(1)\n",
    "print(a,b) #a,b share the same memory location so both changes\n",
    "\n",
    "c=np.ones(2)\n",
    "d=torch.from_numpy(c)\n",
    "print(c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66fee390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7219, 0.9133, 0.4423], requires_grad=True)\n",
      "tensor([2.7219, 2.9133, 2.4423], grad_fn=<AddBackward0>)\n",
      "tensor([14.8177, 16.9742, 11.9294], grad_fn=<MulBackward0>)\n",
      "tensor(14.5737, grad_fn=<MeanBackward0>)\n",
      "tensor([3.6292, 3.8843, 3.2564])\n"
     ]
    }
   ],
   "source": [
    "#Gradient Calculation using Autograd\n",
    "import torch\n",
    "x=torch.rand(3,requires_grad=True)\n",
    "print(x)\n",
    "y=x+2\n",
    "print(y)\n",
    "z=y*y*2\n",
    "print(z)\n",
    "z=z.mean()\n",
    "print(z)\n",
    "\n",
    "z.backward() #dz/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca86df87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6275, 0.4710, 0.1540], requires_grad=True)\n",
      "tensor([0.6275, 0.4710, 0.1540])\n",
      "tensor([0.6275, 0.4710, 0.1540])\n",
      "tensor([0.6275, 0.4710, 0.1540])\n"
     ]
    }
   ],
   "source": [
    "#x.requires_grad_(False)\n",
    "#x.detach()\n",
    "#with torch.no_grad():\n",
    "import torch\n",
    "x=torch.rand(3,requires_grad=True)\n",
    "print(x)\n",
    "x.requires_grad_(False)\n",
    "print(x)\n",
    "y=x.detach()\n",
    "print(y)\n",
    "with torch.no_grad():\n",
    "    y=x+2\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "375f9060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3.])\n",
      "tensor([6., 6., 6.])\n",
      "tensor([9., 9., 9.])\n",
      "tensor([12., 12., 12.])\n",
      "tensor([3., 3., 3.])\n",
      "tensor([3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights=torch.ones(3,requires_grad=True)\n",
    "for _ in range(3):\n",
    "    model_output=(weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)#Since in every iteration previous' iterations value is used so not incorrectgradient is obtained\n",
    "    #weights.grad.zero_()  use this for correct gradient\n",
    "for _ in range(3):\n",
    "    model_output=(weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59142d",
   "metadata": {},
   "source": [
    "# Basic backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbb77dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.)\n",
      "tensor([ 0.2927, -0.8339, -1.0596])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(1.0)\n",
    "w=torch.tensor(1.0,requires_grad=True)\n",
    "y_hat=x*w\n",
    "y=torch.tensor(2.0)\n",
    "\n",
    "loss=(y_hat-y)**2\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "\n",
    "x=torch.rand(3)\n",
    "w=torch.rand(3,requires_grad=True)\n",
    "y_hat=x*w\n",
    "y=torch.rand(3)\n",
    "\n",
    "loss=(y_hat-y)**2\n",
    "v=torch.tensor([1,2,3])\n",
    "loss.backward(v)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2dfeb4",
   "metadata": {},
   "source": [
    "# Prediction using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "364f3de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.2 30.0\n",
      "1.6799999618530272 4.799999\n",
      "1.871999988555908 0.7680002\n",
      "1.9487999868392942 0.12288\n",
      "1.9795200133323667 0.019660834\n",
      "1.9918080282211301 0.0031457357\n",
      "1.9967231869697568 0.000503308\n",
      "1.99868928194046 8.053186e-05\n",
      "1.999475698471069 1.2884395e-05\n",
      "1.999790253639221 2.0613531e-06\n",
      "9.998951268196105\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x=np.array([1,2,3,4],dtype=np.float32)\n",
    "y=np.array([2,4,6,8],dtype=np.float32)\n",
    "\n",
    "w=0.0\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "#loss=1/N(wx-y)^2\n",
    "#dloss/dw=2x/N(wx-y)\n",
    "def gradient(x,y,y_predicted):\n",
    "    return np.dot(2*x,(y_predicted-y)).mean()\n",
    "\n",
    "print(forward(5))\n",
    "\n",
    "learning_rate=0.01\n",
    "\n",
    "for _ in range(10):\n",
    "    y_pred=forward(x)\n",
    "    l=loss(y,y_pred)\n",
    "    grad=gradient(x,y,y_pred)\n",
    "    w-= (learning_rate*grad)\n",
    "    if _%1==0:\n",
    "        print(w,l)\n",
    "    \n",
    "print(forward(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e92d79",
   "metadata": {},
   "source": [
    "# Prediction using Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d9c2a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MulBackward0>)\n",
      "tensor(0.3000, requires_grad=True) tensor(30., grad_fn=<MeanBackward0>)\n",
      "tensor(0.5550, requires_grad=True) tensor(21.6750, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7717, requires_grad=True) tensor(15.6602, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9560, requires_grad=True) tensor(11.3145, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1126, requires_grad=True) tensor(8.1747, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2457, requires_grad=True) tensor(5.9062, grad_fn=<MeanBackward0>)\n",
      "tensor(1.3588, requires_grad=True) tensor(4.2673, grad_fn=<MeanBackward0>)\n",
      "tensor(1.4550, requires_grad=True) tensor(3.0831, grad_fn=<MeanBackward0>)\n",
      "tensor(1.5368, requires_grad=True) tensor(2.2275, grad_fn=<MeanBackward0>)\n",
      "tensor(1.6063, requires_grad=True) tensor(1.6094, grad_fn=<MeanBackward0>)\n",
      "tensor(1.6653, requires_grad=True) tensor(1.1628, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7155, requires_grad=True) tensor(0.8401, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7582, requires_grad=True) tensor(0.6070, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7945, requires_grad=True) tensor(0.4385, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8253, requires_grad=True) tensor(0.3168, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8515, requires_grad=True) tensor(0.2289, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8738, requires_grad=True) tensor(0.1654, grad_fn=<MeanBackward0>)\n",
      "tensor(1.8927, requires_grad=True) tensor(0.1195, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9088, requires_grad=True) tensor(0.0863, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9225, requires_grad=True) tensor(0.0624, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9341, requires_grad=True) tensor(0.0451, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9440, requires_grad=True) tensor(0.0326, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9524, requires_grad=True) tensor(0.0235, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9595, requires_grad=True) tensor(0.0170, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9656, requires_grad=True) tensor(0.0123, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9708, requires_grad=True) tensor(0.0089, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9751, requires_grad=True) tensor(0.0064, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9789, requires_grad=True) tensor(0.0046, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9820, requires_grad=True) tensor(0.0033, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9847, requires_grad=True) tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9870, requires_grad=True) tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9890, requires_grad=True) tensor(0.0013, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9906, requires_grad=True) tensor(0.0009, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9920, requires_grad=True) tensor(0.0007, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9932, requires_grad=True) tensor(0.0005, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9942, requires_grad=True) tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9951, requires_grad=True) tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9958, requires_grad=True) tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9965, requires_grad=True) tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9970, requires_grad=True) tensor(9.3711e-05, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9974, requires_grad=True) tensor(6.7705e-05, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9978, requires_grad=True) tensor(4.8915e-05, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9982, requires_grad=True) tensor(3.5344e-05, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9984, requires_grad=True) tensor(2.5533e-05, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9987, requires_grad=True) tensor(1.8447e-05, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9989, requires_grad=True) tensor(1.3329e-05, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9990, requires_grad=True) tensor(9.6315e-06, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9992, requires_grad=True) tensor(6.9583e-06, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9993, requires_grad=True) tensor(5.0274e-06, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9994, requires_grad=True) tensor(3.6323e-06, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9995, requires_grad=True) tensor(2.6244e-06, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9996, requires_grad=True) tensor(1.8964e-06, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9996, requires_grad=True) tensor(1.3699e-06, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9997, requires_grad=True) tensor(9.8946e-07, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9997, requires_grad=True) tensor(7.1485e-07, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9998, requires_grad=True) tensor(5.1689e-07, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9998, requires_grad=True) tensor(3.7350e-07, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9998, requires_grad=True) tensor(2.6975e-07, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9999, requires_grad=True) tensor(1.9482e-07, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9999, requires_grad=True) tensor(1.4073e-07, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9999, requires_grad=True) tensor(1.0176e-07, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9999, requires_grad=True) tensor(7.3389e-08, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9999, requires_grad=True) tensor(5.3154e-08, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9999, requires_grad=True) tensor(3.8369e-08, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9999, requires_grad=True) tensor(2.7700e-08, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(2.0094e-08, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(1.4520e-08, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(1.0522e-08, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(7.5924e-09, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(5.4872e-09, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(3.9742e-09, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(2.8666e-09, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(2.0563e-09, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(1.4790e-09, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(1.0658e-09, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(7.7187e-10, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(5.5252e-10, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(3.9789e-10, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(2.8820e-10, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(2.0634e-10, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(1.4670e-10, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(1.0177e-10, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(7.3172e-11, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(5.0662e-11, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(3.8074e-11, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(2.7285e-11, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(2.0307e-11, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(1.5348e-11, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(1.1099e-11, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(6.8212e-12, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(5.0768e-12, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(3.5953e-12, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(2.7747e-12, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(1.7053e-12, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(8.9884e-13, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(8.9884e-13, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(8.9884e-13, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(8.9884e-13, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(8.9884e-13, grad_fn=<MeanBackward0>)\n",
      "tensor(2.0000, requires_grad=True) tensor(8.9884e-13, grad_fn=<MeanBackward0>)\n",
      "tensor(10.0000, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "\n",
    "w=torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "print(forward(5))\n",
    "\n",
    "learning_rate=0.01\n",
    "\n",
    "for _ in range(100):\n",
    "    y_pred=forward(x)\n",
    "    l=loss(y,y_pred)\n",
    "    l.backward()\n",
    "    with torch.no_grad():\n",
    "        w-= (learning_rate*w.grad)\n",
    "    \n",
    "    w.grad.zero_()\n",
    "    if _%1==0:\n",
    "        print(w,l)\n",
    "    \n",
    "print(forward(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9b124",
   "metadata": {},
   "source": [
    "# including optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "59bd03ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "3.750857353210449\n",
      "2.7003226280212402 tensor(12.1974, grad_fn=<MseLossBackward0>)\n",
      "1.9968336820602417 tensor(1.5381e-05, grad_fn=<MseLossBackward0>)\n",
      "1.999848484992981 tensor(3.5214e-08, grad_fn=<MseLossBackward0>)\n",
      "1.999992847442627 tensor(8.0945e-11, grad_fn=<MseLossBackward0>)\n",
      "1.9999996423721313 tensor(2.4158e-13, grad_fn=<MseLossBackward0>)\n",
      "2.0 tensor(0., grad_fn=<MseLossBackward0>)\n",
      "2.0 tensor(0., grad_fn=<MseLossBackward0>)\n",
      "2.0 tensor(0., grad_fn=<MseLossBackward0>)\n",
      "2.0 tensor(0., grad_fn=<MseLossBackward0>)\n",
      "2.0 tensor(0., grad_fn=<MseLossBackward0>)\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn #module for neural networks\n",
    "\n",
    "x=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
    "y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
    "x_test=torch.tensor([5],dtype=torch.float32)\n",
    "\n",
    "n_samples,n_features=x.shape\n",
    "print(n_samples,n_features)\n",
    "input_size=n_features\n",
    "output_size=n_features\n",
    "\n",
    "model=nn.Linear(input_size,output_size)\n",
    "print(model(x_test).item())\n",
    "\n",
    "learning_rate=0.1\n",
    "loss=nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for _ in range(1000):\n",
    "    y_pred=model(x)\n",
    "    l=loss(y,y_pred)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if _%100==0:\n",
    "        [w,b]=model.parameters()\n",
    "        print(w[0][0].item(),l)\n",
    "    \n",
    "print(model(x_test).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9308d111",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1298ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#0) prepare data\n",
    "x_numpy,y_numpy=datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=1)\n",
    "x=torch.from_numpy(x_numpy.astype(np.float32))\n",
    "y=torch.from_numpy(y_numpy.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ed626cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "097daa3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75.500000</td>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43.445368</td>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.250000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75.500000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112.750000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "count  150.000000     150.000000    150.000000     150.000000    150.000000\n",
       "mean    75.500000       5.843333      3.054000       3.758667      1.198667\n",
       "std     43.445368       0.828066      0.433594       1.764420      0.763161\n",
       "min      1.000000       4.300000      2.000000       1.000000      0.100000\n",
       "25%     38.250000       5.100000      2.800000       1.600000      0.300000\n",
       "50%     75.500000       5.800000      3.000000       4.350000      1.300000\n",
       "75%    112.750000       6.400000      3.300000       5.100000      1.800000\n",
       "max    150.000000       7.900000      4.400000       6.900000      2.500000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('iris.csv')\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "599da302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X = dataset.iloc[:, [0,1,2, 3]].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "257eda14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71fc9f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, solver='lbfgs', multi_class='auto')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42b34c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming binary classification\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4c0fc854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X = dataset.iloc[:, [0,1,2, 3]].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "836040f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9809881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f2e49ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming binary classification\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47abedcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, solver='lbfgs', multi_class='auto')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c90d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test     | y_pred     | Setosa(%)  | versicolor(%) | virginica(%)\n",
      "-----------------------------------------------------------------\n",
      "2.4        | 14         | 0.0        | 0.01          | 0.0       \n",
      "1.0        | 9          | 0.01       | 0.01          | 0.01      \n",
      "0.2        | 1          | 0.05       | 0.43          | 0.04      \n",
      "1.8        | 17         | 0.0        | 0.0           | 0.0       \n",
      "0.2        | 1          | 0.14       | 0.6           | 0.11      \n",
      "2.5        | 14         | 0.0        | 0.0           | 0.0       \n",
      "0.3        | 1          | 0.1        | 0.65          | 0.08      \n",
      "1.5        | 10         | 0.0        | 0.01          | 0.0       \n",
      "1.4        | 11         | 0.0        | 0.01          | 0.0       \n",
      "1.3        | 9          | 0.02       | 0.04          | 0.02      \n",
      "1.4        | 15         | 0.0        | 0.0           | 0.0       \n",
      "1.5        | 10         | 0.02       | 0.03          | 0.02      \n",
      "1.2        | 9          | 0.01       | 0.02          | 0.01      \n",
      "1.5        | 9          | 0.01       | 0.01          | 0.01      \n",
      "1.4        | 9          | 0.01       | 0.02          | 0.01      \n",
      "0.1        | 1          | 0.13       | 0.57          | 0.1       \n",
      "1.5        | 9          | 0.01       | 0.02          | 0.01      \n",
      "1.2        | 9          | 0.01       | 0.02          | 0.01      \n",
      "0.3        | 1          | 0.13       | 0.57          | 0.1       \n",
      "0.4        | 1          | 0.08       | 0.55          | 0.06      \n",
      "2.0        | 14         | 0.01       | 0.01          | 0.01      \n",
      "1.5        | 9          | 0.03       | 0.05          | 0.03      \n",
      "0.2        | 1          | 0.15       | 0.56          | 0.11      \n",
      "0.2        | 1          | 0.18       | 0.54          | 0.13      \n",
      "1.8        | 14         | 0.0        | 0.0           | 0.0       \n",
      "0.2        | 1          | 0.12       | 0.69          | 0.09      \n",
      "0.4        | 1          | 0.09       | 0.53          | 0.07      \n",
      "1.3        | 9          | 0.01       | 0.02          | 0.01      \n",
      "1.0        | 6          | 0.02       | 0.04          | 0.02      \n",
      "0.4        | 1          | 0.13       | 0.59          | 0.1       \n",
      "1.8        | 19         | 0.0        | 0.0           | 0.0       \n",
      "1.5        | 9          | 0.03       | 0.05          | 0.03      \n",
      "0.2        | 1          | 0.11       | 0.6           | 0.09      \n",
      "1.8        | 14         | 0.0        | 0.01          | 0.0       \n",
      "2.2        | 14         | 0.0        | 0.0           | 0.0       \n",
      "1.4        | 9          | 0.05       | 0.07          | 0.04      \n",
      "0.3        | 1          | 0.07       | 0.47          | 0.06      \n",
      "1.6        | 9          | 0.01       | 0.01          | 0.01      \n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Predict probabilities\n",
    "probs_y=classifier.predict_proba(X_test)\n",
    "### Print results \n",
    "probs_y = np.round(probs_y, 2)\n",
    "res = \"{:<10} | {:<10} | {:<10} | {:<13} | {:<5}\".format(\"y_test\", \"y_pred\", \"Setosa(%)\", \"versicolor(%)\", \"virginica(%)\\n\")\n",
    "res += \"-\"*65+\"\\n\"\n",
    "res += \"\\n\".join(\"{:<10} | {:<10} | {:<10} | {:<13} | {:<10}\".format(x, y, a, b, c) for x, y, a, b, c in zip(y_test, y_pred, probs_y[:,0], probs_y[:,1], probs_y[:,2]))\n",
    "res += \"\\n\"+\"-\"*65+\"\\n\"\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c3eea",
   "metadata": {},
   "source": [
    "# Again "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cf5e62",
   "metadata": {},
   "source": [
    "# Logistic regression on IRIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fa507a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5ee18039",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e7dd4821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "count     150.000000    150.000000     150.000000    150.000000\n",
       "mean        5.843333      3.054000       3.758667      1.198667\n",
       "std         0.828066      0.433594       1.764420      0.763161\n",
       "min         4.300000      2.000000       1.000000      0.100000\n",
       "25%         5.100000      2.800000       1.600000      0.300000\n",
       "50%         5.800000      3.000000       4.350000      1.300000\n",
       "75%         6.400000      3.300000       5.100000      1.800000\n",
       "max         7.900000      4.400000       6.900000      2.500000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64ed1086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   SepalLengthCm  150 non-null    float64\n",
      " 1   SepalWidthCm   150 non-null    float64\n",
      " 2   PetalLengthCm  150 non-null    float64\n",
      " 3   PetalWidthCm   150 non-null    float64\n",
      " 4   Species        150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cf481a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X = dataset.iloc[:, [0,1,2, 3]].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dfa7769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c07281a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, solver='lbfgs', multi_class='auto')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d565bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dd1ecf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "probs_y=classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8207b6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test     | y_pred     | Setosa(%)  | versicolor(%) | virginica(%)\n",
      "-----------------------------------------------------------------\n",
      "virginica  | virginica  | 0.0        | 0.03          | 0.97      \n",
      "versicolor | versicolor | 0.01       | 0.95          | 0.04      \n",
      "setosa     | setosa     | 1.0        | 0.0           | 0.0       \n",
      "virginica  | virginica  | 0.0        | 0.08          | 0.92      \n",
      "setosa     | setosa     | 0.98       | 0.02          | 0.0       \n",
      "virginica  | virginica  | 0.0        | 0.01          | 0.99      \n",
      "setosa     | setosa     | 0.98       | 0.02          | 0.0       \n",
      "versicolor | versicolor | 0.01       | 0.71          | 0.28      \n",
      "versicolor | versicolor | 0.0        | 0.73          | 0.27      \n",
      "versicolor | versicolor | 0.02       | 0.89          | 0.08      \n",
      "virginica  | virginica  | 0.0        | 0.44          | 0.56      \n",
      "versicolor | versicolor | 0.02       | 0.76          | 0.22      \n",
      "versicolor | versicolor | 0.01       | 0.85          | 0.13      \n",
      "versicolor | versicolor | 0.0        | 0.69          | 0.3       \n",
      "versicolor | versicolor | 0.01       | 0.75          | 0.24      \n",
      "setosa     | setosa     | 0.95       | 0.05          | 0.0       \n",
      "versicolor | versicolor | 0.02       | 0.72          | 0.26      \n",
      "versicolor | versicolor | 0.03       | 0.86          | 0.11      \n",
      "setosa     | setosa     | 0.94       | 0.06          | 0.0       \n",
      "setosa     | setosa     | 0.99       | 0.01          | 0.0       \n",
      "virginica  | virginica  | 0.0        | 0.17          | 0.83      \n",
      "versicolor | versicolor | 0.04       | 0.71          | 0.25      \n",
      "setosa     | setosa     | 0.98       | 0.02          | 0.0       \n",
      "setosa     | setosa     | 0.96       | 0.04          | 0.0       \n",
      "virginica  | virginica  | 0.0        | 0.35          | 0.65      \n",
      "setosa     | setosa     | 1.0        | 0.0           | 0.0       \n",
      "setosa     | setosa     | 0.99       | 0.01          | 0.0       \n",
      "versicolor | versicolor | 0.02       | 0.87          | 0.11      \n",
      "versicolor | versicolor | 0.09       | 0.9           | 0.02      \n",
      "setosa     | setosa     | 0.97       | 0.03          | 0.0       \n",
      "virginica  | virginica  | 0.0        | 0.21          | 0.79      \n",
      "versicolor | versicolor | 0.06       | 0.69          | 0.25      \n",
      "setosa     | setosa     | 0.98       | 0.02          | 0.0       \n",
      "virginica  | virginica  | 0.0        | 0.35          | 0.65      \n",
      "virginica  | virginica  | 0.0        | 0.04          | 0.96      \n",
      "versicolor | versicolor | 0.07       | 0.81          | 0.11      \n",
      "setosa     | setosa     | 0.97       | 0.03          | 0.0       \n",
      "versicolor | virginica  | 0.0        | 0.42          | 0.58      \n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs_y = np.round(probs_y, 2)\n",
    "res = \"{:<10} | {:<10} | {:<10} | {:<13} | {:<5}\".format(\"y_test\", \"y_pred\", \"Setosa(%)\", \"versicolor(%)\", \"virginica(%)\\n\")\n",
    "res += \"-\"*65+\"\\n\"\n",
    "res += \"\\n\".join(\"{:<10} | {:<10} | {:<10} | {:<13} | {:<10}\".format(x, y, a, b, c) for x, y, a, b, c in zip(y_test, y_pred, probs_y[:,0], probs_y[:,1], probs_y[:,2]))\n",
    "res += \"\\n\"+\"-\"*65+\"\\n\"\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "26edbbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c5ea8823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# confusion matrix sns heatmap \n",
    "## https://www.kaggle.com/agungor2/various-confusion-matrix-plots\n",
    "ax = plt.axes()\n",
    "df_cm = cm\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 30}, fmt='d',cmap=\"Blues\", ax = ax )\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c971c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
